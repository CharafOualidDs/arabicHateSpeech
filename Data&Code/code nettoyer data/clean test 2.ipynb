{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521280a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# Téléchargement des ressources nécessaires de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f408e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('clean_fusionne.csv')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert non-string data to string\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Remove English words\n",
    "    text = re.sub(r'[a-zA-Z]+', '', text)\n",
    "    # Remove usernames\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http.?://[^\\s]+[\\s]?', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub('[^ا-ي]', ' ', text)\n",
    "    # Reduce sequences of repeated letters to a single letter\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    # Tokenize text\n",
    "    text = simple_word_tokenize(text)\n",
    "    # Remove single-letter words\n",
    "    text = [word for word in text if len(word) > 1]\n",
    "    # Convert tokens back into a string\n",
    "    text = ' '.join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd1c8b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Toxic/Not Toxic\n",
      "0  يبغي التنبيه على ان السعودية تستخدم صواريخ جو ...                1\n",
      "1  مريكا قتلت بالامس معوق رفض رفع يديه فماذا تريد...                1\n",
      "2  هذا الشخص هو من كان يد لاحتلال العراق وضرب افغ...                1\n",
      "3  الى جمال ريان مذيع الجزيرة نحن من رعاك فى المه...                1\n",
      "4  خيبة ال مل ليست تشا ما ولا تقولا عزم لكفالة ال...                0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace NaN values with empty strings\n",
    "df['Text'] = df['Text'].fillna('')\n",
    "\n",
    "# Apply the preprocessing function\n",
    "df['Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6715bb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
